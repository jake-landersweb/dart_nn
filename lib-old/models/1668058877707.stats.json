{"date":"2022-11-09 21:41:17.948264","dataset":"all_data","shape":[[784,200],[200,10]],"layers":[{"activation":"relu","weightRegL1":0.0,"weightRegL2":0.0005,"biasRegL1":0.0,"biasRegL2":0.0005,"inputs":784,"neurons":200,"shape":[784,200]},{"activation":"softmax","weightRegL1":0.0,"weightRegL2":0.0,"biasRegL1":0.0,"biasRegL2":0.0,"inputs":200,"neurons":10,"shape":[200,10]}],"batchSize":128,"accuracy":0.9135703566384181,"lossFunction":"cat_ce","optimizer":{"name":"adam","learningRate":0.005,"currentLearningRate":0.002072538860103627,"decay":0.0005,"iterations":2826,"epsilon":1e-7,"beta1":0.9,"beta2":0.999},"seed":43543,"metadata":"Model uses all of the mnist data variations, used to show how improvements in data prep can lower models performace in testing, but make it better at generalizing to actual hand written digits."}